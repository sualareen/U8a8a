library(RMeCab)
library(dplyr)
library(readr)
library(purrr)
#引入词频表
#读入文档
df_csv <-
  read_csv("C:/Users/Administrator/Desktop/forMiniToolsTemp/example.csv")

# 使用 RMeCabC 函数解析文件
result <- RMeCabText("C:/Users/Administrator/Desktop/forMiniToolsTemp/text.txt")
#转置数据框
df <- as.data.frame(t(data.frame(result)))

#筛选器
labels <- c("動詞","形容詞","感動詞","接続詞","接頭詞","動詞","名詞","副詞","連体詞")
#筛选器核心语法
#target_df <- df_csv %>% filter(df_csv[[column_name]] == label) 
filted_df <- df %>% 
  filter(V2 %in% labels)

#一些小工具
#元素唯一化
column_name <- colnames(filted_df)[1]#第一列
unique_df <- distinct(filted_df, .keep_all = FALSE, !!sym(column_name))

#遍历每个单词
# 遍历 unique_df 中的每个单词，并在 df_csv 中提取相应的行 
column_name_02 <- colnames(df_csv)[1]
extracted_rows <- map_dfr(unique_df[[1]], function(word) { df_csv %>% 
    filter(!is.na(df_csv[[column_name_02]]) & 
             df_csv[[column_name_02]] == word) })

# 计算补集
#这段代码要重新写，它把有些所有的词频都算进去了，算了多次，有些又没有，没有的单词有500多个
# 确保列名一致 
colnames(extracted_rows)[1] <- colnames(unique_df)[1]
complement_df <- anti_join(unique_df, extracted_rows, by = colnames(unique_df)[1])
# 查看结果
print(target_df)
